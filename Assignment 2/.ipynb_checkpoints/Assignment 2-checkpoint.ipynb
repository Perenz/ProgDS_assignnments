{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID2214/FID3214 Assignment 2 Group no. [enter]\n",
    "### Project members: \n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "[Enter Name, email]\n",
    "\n",
    "### Declaration:\n",
    "By submitting this solution, it is hereby declared that all individuals listed above have contributed to the solution, either with code that appear in the final solution below, or with code that has been evaluated and compared to the final solution, but for some reason has been excluded. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.\n",
    "\n",
    "It is furthermore declared that the code below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course ID2214/FID3214) and no part of the solution has been provided by someone not listed as project member above.\n",
    "\n",
    "It is furthermore declared that it has been understood that no other library/package than the Python 3 standard library, NumPy, pandas and time may be used in the solution for this assignment.\n",
    "\n",
    "### Instructions\n",
    "All parts of the assignment starting with number 1 below are mandatory. Satisfactory solutions\n",
    "will give 1 point (in total). If they in addition are good (all parts work more or less \n",
    "as they should), completed on time (submitted before the deadline in Canvas) and according\n",
    "to the instructions, together with satisfactory solutions of all parts of the assignment starting \n",
    "with number 2 below, then the assignment will receive 2 points (in total).\n",
    "\n",
    "Note that you do not have to develop the code directly within the notebook\n",
    "but may instead copy the comments and test cases to a more convenient development environment\n",
    "and when everything works as expected, you may paste your functions into this\n",
    "notebook, do a final testing (all cells should succeed) and submit the whole notebook \n",
    "(a single file) in Canvas (do not forget to fill in your group number and names above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reused functions from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste functions from Assignment 1 here that you need for this assignment\n",
    "def create_column_filter(df): \n",
    "    exempt = [\"CLASS\"]\n",
    "    col_filter = exempt.copy()\n",
    "    for col in df.columns: \n",
    "        if col not in exempt: \n",
    "            if (not df[col].isnull().values.all()) and (df[col].nunique() > 1): \n",
    "                col_filter.append(col)\n",
    "    filtered = df.copy()\n",
    "    filtered = filtered.loc[:, col_filter]\n",
    "    return filtered, col_filter\n",
    "\n",
    "def apply_column_filter(df, column_filter):\n",
    "    return df[column_filter]\n",
    "\n",
    "def create_normalization(df, normalizationtype='minmax'):\n",
    "    to_rtn = df.copy()\n",
    "    norm_dict = {}\n",
    "    colu = to_rtn.columns\n",
    "    print(colu)\n",
    "    for col in colu:\n",
    "        #Check if col is numeric\n",
    "        if pd.api.types.is_numeric_dtype(to_rtn[col]) and col not in ['CLASS', 'ID']:\n",
    "            if normalizationtype == 'minmax':\n",
    "                max = to_rtn[col].max()\n",
    "                min = to_rtn[col].min()\n",
    "                norm_dict[col] = (normalizationtype, min, max)\n",
    "                #Normalize using minamx\n",
    "                to_rtn[col] = to_rtn[col].apply(lambda x: (x-min)/(max-min))\n",
    "            if normalizationtype == 'zscore':\n",
    "                mean = to_rtn[col].mean()\n",
    "                std = to_rtn[col].std()\n",
    "                norm_dict[col] = ('zscore', mean, std)\n",
    "                #Normalizing using zscore\n",
    "                to_rtn[col] = to_rtn[col].apply(lambda x: (x-mean)/std)\n",
    "    return to_rtn, norm_dict\n",
    "\n",
    "def apply_normalization(df, norm_dict):\n",
    "  to_rtn = df.copy()\n",
    "  for col in to_rtn.columns:\n",
    "    if pd.api.types.is_numeric_dtype(to_rtn[col]) and col not in ['CLASS', 'ID']:\n",
    "        min = norm_dict[col][1]\n",
    "        mean = norm_dict[col][1]\n",
    "        max = std = norm_dict[col][2]\n",
    "        normtype = norm_dict[col][0]\n",
    "        if normtype == 'minmax':\n",
    "            val_list = []\n",
    "            # Calculate the normalized value in the range [0,1]\n",
    "            for x in to_rtn[col]:\n",
    "                v = (x-min)/(max-min)\n",
    "                if v > 1.0:\n",
    "                    v = 1\n",
    "                if v < 0.0:\n",
    "                    v = 0\n",
    "                val_list.append(v)\n",
    "            to_rtn[col] = val_list\n",
    "            #to_rtn[col] = to_rtn[col].apply(lambda x: (x-min)/(max-min)) #Have to consider the [0,1] range\n",
    "        if normtype == 'zscore':\n",
    "            #Normalize with zscore\n",
    "            to_rtn[col] = to_rtn[col].apply(lambda x: (x-mean)/std)\n",
    "  return to_rtn\n",
    "\n",
    "def create_imputation(df):\n",
    "    to_rtn = df.copy()\n",
    "    imp_dict = {}\n",
    "    for col in to_rtn.columns:\n",
    "        if col not in ['CLASS', 'ID']:\n",
    "            if to_rtn[col].dtypes == \"int\" or to_rtn[col].dtype == \"float\":\n",
    "                val = to_rtn[col].mean()\n",
    "                to_rtn[col] = to_rtn[col].fillna(value=val)\n",
    "            else:\n",
    "                #Get first value of the mode, alternatively np.random could be used\n",
    "                val = to_rtn[col].mode()[0]\n",
    "                to_rtn[col] = to_rtn[col].fillna(value=val)\n",
    "            imp_dict[col] = val\n",
    "    #to_rtn = to_rtn.fillna(value=imp_dict)\n",
    "    return to_rtn, imp_dict\n",
    "\n",
    "\n",
    "def apply_imputation(df, imputation):\n",
    "    to_rtn = df.copy()\n",
    "    #No check for columns type because only rights type are included in the imputation dictionary\n",
    "    to_rtn = to_rtn.fillna(value=imputation)\n",
    "    return to_rtn\n",
    "\n",
    "def create_bins(df, nobins=10, bintype='equal-width'):\n",
    "    to_rtn = df.copy()\n",
    "    bins = {}\n",
    "    for col in to_rtn.columns:\n",
    "        if col != \"CLASS\" and col != \"ID\" and df[col].dtype in [\"float64\", \"float32\", \"int64\", \"int32\"]:\n",
    "            if bintype == \"equal-width\":\n",
    "                to_rtn[col], binR = pd.cut(to_rtn[col],nobins,retbins=True,duplicates=\"drop\",labels=False)\n",
    "                bins[col] = binR    \n",
    "            elif bintype == \"equal-size\":\n",
    "                to_rtn[col], binR = pd.qcut(to_rtn[col],q=nobins,retbins=True,duplicates=\"drop\",labels=False)\n",
    "                bins[col] = binR\n",
    "            to_rtn[col] = to_rtn[col].astype(\"category\")\n",
    "            to_rtn[col] = to_rtn[col].cat.set_categories([str(i) for i in to_rtn[col].cat.categories], rename = True)\n",
    "            #Infinity edges\n",
    "            bins[col][0] = -np.inf\n",
    "            bins[col][-1] = np.inf\n",
    "        else:\n",
    "            to_rtn[col] = to_rtn[col].astype('category')\n",
    "    return to_rtn, bins\n",
    "\n",
    "def apply_bins(df, binning): \n",
    "    exempt = [\"ID\", \"CLASS\"]\n",
    "    binned_df = df.copy()\n",
    "    for col in binned_df.columns: \n",
    "        if col not in exempt: \n",
    "            if binned_df[col].dtype == \"int64\" or binned_df[col].dtype == \"float64\": \n",
    "                bins = binning[col]\n",
    "                bin_length = len(bins) - 1\n",
    "                labels = np.arange(0, bin_length, 1)\n",
    "                binned_df[col] = pd.cut(binned_df[col], bins, labels=labels)\n",
    "                binned_df[col] = binned_df[col].astype('category')\n",
    "    return binned_df\n",
    "\n",
    "def create_one_hot(df):\n",
    "    to_rtn = df\n",
    "    enc = {}\n",
    "    for col in [el for el in to_rtn.columns if el not in ['CLASS', 'ID']]:\n",
    "        #Check for columns type\n",
    "        if str(to_rtn.dtypes[col]) == \"category\" or str(to_rtn.dtypes[col]) == \"object\":\n",
    "            #Convert columns to category\n",
    "            to_rtn[col] = to_rtn[col].astype(\"category\")\n",
    "            #For each column, get the list of categories\n",
    "            enc[col] = list(to_rtn[col].cat.categories)\n",
    "            for i in enc[col]:\n",
    "                tit = col + '_' + str(i) #Name of the new column\n",
    "                col_enc = to_rtn[col] == i\n",
    "                col_enc = col_enc.astype(\"int\")\n",
    "                df_enc = col_enc\n",
    "            df_enc = df_enc.drop(axis=1, columns=col)\n",
    "            \n",
    "    return df_enc, enc\n",
    "\n",
    "\n",
    "def apply_one_hot(df,one_hot):\n",
    "    df_new = df.copy()\n",
    "    for col in df.columns:\n",
    "        if col in one_hot:    \n",
    "            for i in one_hot[col]:\n",
    "                name = col + \"_\" + str(i)\n",
    "                new_col = df[col]==i\n",
    "                new_col = pd.Series(new_col.astype(\"int\"))\n",
    "                df_new[name] = new_col\n",
    "            df_new = df_new.drop(columns = col, axis = 1)\n",
    "            \n",
    "    return df_new\n",
    "\n",
    "def split(df, testfraction = 0.5): \n",
    "    df_length = len(df)\n",
    "    cut_off = df_length * testfraction\n",
    "    cut_off = int(cut_off)\n",
    "    indexes = np.random.permutation(df.index)\n",
    "    test_indexes = indexes[0:cut_off]\n",
    "    training_indexes = indexes[cut_off:]\n",
    "    trainingdf = df.iloc[training_indexes, :]\n",
    "    testdf = df.iloc[test_indexes, :]\n",
    "    return trainingdf, testdf\n",
    "\n",
    "def accuracy(df, correctlabels):\n",
    "    labels = df.idxmax(axis=1)\n",
    "    truelabels = (labels == correctlabels).sum()\n",
    "    accuracy = truelabels/len(df)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def folds(df, nofolds=10):\n",
    "    to_rtn = df.copy()\n",
    "    to_rtn = np.random.permutation(to_rtn.index)\n",
    "    fold = []\n",
    "    \n",
    "    for i in range(nofolds):\n",
    "            fold.append(df[int(i*len(df)/nofolds):int((i+1)*len(df)/nofolds)])\n",
    "            \n",
    "    return fold\n",
    "\n",
    "def brier_score(df, correctlabels): \n",
    "    label_df = pd.get_dummies(correctlabels)\n",
    "    brier_score = np.mean(np.sum((df - label_df)**2, axis=1))\n",
    "    \n",
    "    return brier_score\n",
    "\n",
    "def auc(df, correctlabels):   \n",
    "    cols = df.columns\n",
    "    cor_list = [(c == cols) for c in correctlabels]\n",
    "    #print(cor_list)\n",
    "    correct_filter = pd.DataFrame(cor_list, columns=cols)\n",
    "\n",
    "    # Calculate binary AUC for each class label\n",
    "    # Treating the predicted probability of this class for each instance as a score\n",
    "    AUC = 0\n",
    "    for col in df.columns:     \n",
    "        # Map from each score to an array with number of true positives and true negative\n",
    "        class_score = {score: [0, 0] for score in df[col]} # [positive, negative]\n",
    "        \n",
    "        for i in range(len(df[col])):  \n",
    "            # We find score of the true positives and then the ones of true negatives\n",
    "            score = df[col][i] # probability of class col row n\n",
    "            is_positive = correct_filter[col][i] == True\n",
    "            class_score[score] = [class_score[score][0] + is_positive,\n",
    "                                  class_score[score][1] + ~is_positive]\n",
    "        #We create a single reversed list of pairs\n",
    "        sort_score = sorted(class_score, reverse=True)\n",
    "        sorted_list = np.array([class_score[score] for score in sort_score])\n",
    "        \n",
    "        class_auc = cov_tp = 0\n",
    "        tp, fp = sorted_list[:, 0], sorted_list[:, 1] \n",
    "        tot_tp, tot_fp = sum(tp), sum(fp)\n",
    "        \n",
    "        #Evaluate the AUC considering the 3 different cases\n",
    "        for i in range(len(tp)):   \n",
    "            if fp[i] == 0:\n",
    "                #Increase up the. y-axis\n",
    "                cov_tp += tp[i]\n",
    "            elif tp[i] == 0:\n",
    "                #Have rectangle to calculate\n",
    "                class_auc += (cov_tp/tot_tp)*(fp[i]/tot_fp)\n",
    "            else: \n",
    "                class_auc += (cov_tp/tot_tp)*(fp[i]/tot_fp)+(tp[i]/tot_tp)*(fp[i]/tot_fp)/2\n",
    "                cov_tp += tp[i]\n",
    "                \n",
    "        frequency = dict(pd.Series(correctlabels).value_counts(normalize=True))\n",
    "        AUC += frequency[col]*class_auc\n",
    "    return AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the class kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class kNN with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self - the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# <nothing>\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# column_filter, imputation, normalization, one_hot, labels, training_labels, training_data, training_time\n",
    "#\n",
    "# Input to fit:\n",
    "# self              - the object itself\n",
    "# df                - a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# normalizationtype - \"minmax\" (default) or \"zscore\"\n",
    "#\n",
    "# Output from fit:\n",
    "# <nothing>\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.column_filter   - a column filter (see Assignment 1) from df\n",
    "# self.imputation      - an imputation mapping (see Assignment 1) from df\n",
    "# self.normalization   - a normalization mapping (see Assignment 1), using normalizationtype from the imputed df\n",
    "# self.one_hot         - a one-hot mapping (see Assignment 1)\n",
    "# self.training_labels - a pandas series corresponding to the \"CLASS\" column, set to be of type \"category\" \n",
    "# self.labels          - a list of the categories (class labels) of the previous series\n",
    "# self.training_data   - the values (an ndarray) of the transformed dataframe, i.e., after employing imputation, \n",
    "#                        normalization, and possibly one-hot encoding, and also after removing the \"CLASS\" and \"ID\" columns\n",
    "#\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Input to predict:\n",
    "# self - the object itself\n",
    "# df   - a dataframe\n",
    "# k    - an integer >= 1 (default = 5)\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions - a dataframe with class labels as column names and the rows corresponding to\n",
    "#               predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#               are estimated by the relative class frequencies in the set of class labels from the k nearest \n",
    "#               (with respect to Euclidean distance) neighbors in training_data\n",
    "#\n",
    "# Hint 1: Drop any \"CLASS\" and \"ID\" columns first and then apply column filtering, imputation, normalization and one-hot\n",
    "#\n",
    "# Hint 2: Get the numerical values (as an ndarray) from the resulting dataframe and iterate over the rows \n",
    "#         calling some sub-function, e.g., get_nearest_neighbor_predictions(x_test,k), which for a test row\n",
    "#         (numerical input feature values) finds the k nearest neighbors and calculate the class probabilities.\n",
    "#\n",
    "# Hint 3: This sub-function may first find the distances to all training instances, e.g., pairs consisting of\n",
    "#         training instance index and distance, and then sort them according to distance, and then (using the indexes\n",
    "#         of the k closest instances) find the corresponding labels and calculate the relative class frequencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.01 s.\n",
      "Testing time (k=1): 0.14 s.\n",
      "Testing time (k=3): 0.15 s.\n",
      "Testing time (k=5): 0.15 s.\n",
      "Testing time (k=7): 0.15 s.\n",
      "Testing time (k=9): 0.15 s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.810350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.488058</td>\n",
       "      <td>0.815859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.471028</td>\n",
       "      <td>0.833843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.471867</td>\n",
       "      <td>0.833481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.482981</td>\n",
       "      <td>0.827727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Brier score       AUC\n",
       "1  0.747664     0.504673  0.810350\n",
       "3  0.663551     0.488058  0.815859\n",
       "5  0.579439     0.471028  0.833843\n",
       "7  0.598131     0.471867  0.833481\n",
       "9  0.616822     0.482981  0.827727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.csv\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.csv\")\n",
    "\n",
    "knn_model = kNN()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "knn_model.fit(glass_train_df)\n",
    "print(\"Training time: {0:.2f} s.\".format(time.perf_counter()-t0))\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "k_values = [1,3,5,7,9]\n",
    "results = np.empty((len(k_values),3))\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = knn_model.predict(glass_test_df,k=k_values[i])\n",
    "    print(\"Testing time (k={0}): {1:.2f} s.\".format(k_values[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=k_values,columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "print()\n",
    "display(\"results\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (k=1): 1.0000\n",
      "AUC on training set (k=1): 1.0000\n",
      "Brier score on training set (k=1): 0.0000\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "predictions = knn_model.predict(glass_train_df,k=1)\n",
    "print(\"Accuracy on training set (k=1): {0:.4f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set (k=1): {0:.4f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set (k=1): {0:.4f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class NaiveBayes with three functions __init__, fit and predict (after the comments):\n",
    "#\n",
    "# Input to __init__: \n",
    "# self - the object itself\n",
    "#\n",
    "# Output from __init__:\n",
    "# <nothing>\n",
    "# \n",
    "# This function does not return anything but just initializes the following attributes of the object (self) to None:\n",
    "# column_filter, binning, labels, class_priors, feature_class_value_counts, feature_class_counts\n",
    "#\n",
    "# Input to fit:\n",
    "# self    - the object itself\n",
    "# df      - a dataframe (where the column names \"CLASS\" and \"ID\" have special meaning)\n",
    "# nobins  - no. of bins (default = 10)\n",
    "# bintype - either \"equal-width\" (default) or \"equal-size\" \n",
    "#\n",
    "# Output from fit:\n",
    "# <nothing>\n",
    "#\n",
    "# The result of applying this function should be:\n",
    "#\n",
    "# self.column_filter              - a column filter (see Assignment 1) from df\n",
    "# self.binning                    - a discretization mapping (see Assignment 1) from df\n",
    "# self.class_priors               - a mapping (dictionary) from the labels (categories) of the \"CLASS\" column of df,\n",
    "#                                   to the relative frequencies of the labels\n",
    "# self.labels                     - a list of the categories (class labels) of the \"CLASS\" column of df\n",
    "# self.feature_class_value_counts - a mapping from the feature (column name) to the number of\n",
    "#                                   training instances with a specific combination of (non-missing, categorical) \n",
    "#                                   value for the feature and class label\n",
    "# self.feature_class_counts       - a mapping from the feature (column name) to the number of\n",
    "#                                   training instances with a specific class label and some (non-missing, categorical) \n",
    "#                                   value for the feature\n",
    "#\n",
    "# Note that the function does not return anything but just assigns values to the attributes of the object.\n",
    "#\n",
    "# Input to predict:\n",
    "# self - the object itself\n",
    "# df   - a dataframe\n",
    "# \n",
    "# Output from predict:\n",
    "# predictions - a dataframe with class labels as column names and the rows corresponding to\n",
    "#               predictions with estimated class probabilities for each row in df, where the class probabilities\n",
    "#               are estimated by the naive approximation of Bayes rule (see lecture slides)\n",
    "#\n",
    "# Hint 1: First apply the column filter and discretization\n",
    "#\n",
    "# Hint 2: Iterating over either columns or rows, and for each possible class label, calculate the relative\n",
    "#         frequency of the observed feature value given the class (using feature_class_value_counts and \n",
    "#         feature_class_counts) \n",
    "#\n",
    "# Hint 3: Calculate the non-normalized estimated class probabilities by multiplying the class priors to the\n",
    "#         product of the relative frequencies\n",
    "#\n",
    "# Hint 4: Normalize the probabilities by dividing by the sum of the non-normalized probabilities; in case\n",
    "#         this sum is zero, then set the probabilities to the class priors\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        #column_filter, binning, labels, class_priors, feature_class_value_counts, feature_class_counts\n",
    "        self.column_filter = None\n",
    "        self.binning = None\n",
    "        self.labels = None\n",
    "        self.class_priors = None\n",
    "        self.feature_class_value_counts = None\n",
    "        self.feature_class_counts = None\n",
    "\n",
    "    def fit(self, df, nobins=10, bintype='equal-width'):\n",
    "        # self.column_filter              - a column filter (see Assignment 1) from df\n",
    "        # self.binning                    - a discretization mapping (see Assignment 1) from df\n",
    "        # self.class_priors               - a mapping (dictionary) from the labels (categories) of the \"CLASS\" column of df,\n",
    "        #                                   to the relative frequencies of the labels\n",
    "        # self.labels                     - a list of the categories (class labels) of the \"CLASS\" column of df\n",
    "        # self.feature_class_value_counts - a mapping from the feature (column name) to the number of\n",
    "        #                                   training instances with a specific combination of (non-missing, categorical) \n",
    "        #                                   value for the feature and class label\n",
    "        # self.feature_class_counts       - a mapping from the feature (column name) to the number of\n",
    "        #                                   training instances with a specific class label and some (non-missing, categorical) \n",
    "        #                                   value for the feature\n",
    "        df_c = df.copy()\n",
    "        df_c, self.column_filter = create_column_filter(df_c)\n",
    "        df_c, self.binning = create_bins(df_c, nobins, bintype)\n",
    "        self.feature_class_value_counts = {}\n",
    "        self.feature_class_counts = {} #Each element is a dict with keys for each possible label\n",
    "        \n",
    "        #Compute relative frequency of the \"Class\" label\n",
    "        val_c = df_c['CLASS'].value_counts()\n",
    "        self.class_priors = {k:v for k,v in val_c.items()}\n",
    "        #print(self.class_priors)\n",
    "        \n",
    "        '''\n",
    "        #ctr = df_c['CLASS'].size\n",
    "        #self.class_priors = {}\n",
    "        for col, r in df_c.iterrows():\n",
    "            \n",
    "                l = r['CLASS']\n",
    "                #Check for nan values??\n",
    "                if self.class_priors.get(l, None) is not None:\n",
    "                    self.class_priors[l] += 1/ctr\n",
    "                else:\n",
    "                    self.class_priors[l] = 0\n",
    "            \n",
    "\n",
    "            \n",
    "            if not pd.isna(r['CLASS']):\n",
    "                i=0\n",
    "                for col, v in r.items():\n",
    "                    if not pd.isna(r[col]) and df_c[col].dtype == 'category' and col not in ['CLASS', 'ID']:\n",
    "                        if self.feature_class_value_counts.get(col, None) is None:\n",
    "                            self.feature_class_value_counts[col] = {}\n",
    "                        if self.feature_class_value_counts[col].get(v, None) is None:\n",
    "                            self.feature_class_value_counts[col][v] = {}\n",
    "                        #Increase the count\n",
    "                        self.feature_class_value_counts[col][v][r['CLASS']] = self.feature_class_value_counts.get(col, {}).get(v, {}).get(r['CLASS'], 0) + 1\n",
    "                        if self.feature_class_counts.get(col, None) is None:\n",
    "                            self.feature_class_counts[col] = {}\n",
    "                        self.feature_class_counts[col][r['CLASS']] = self.feature_class_counts.get(col, {}).get(r['CLASS'], 0) + 1\n",
    "        '''   \n",
    "        for  col in df_c.columns.drop(['CLASS', 'ID']):\n",
    "            self.feature_class_value_counts[col] = {}\n",
    "            for (names, group) in df_c.groupby(['CLASS', col]):\n",
    "                self.feature_class_value_counts[col][names[0], names[1]] = len(group)\n",
    "                \n",
    "    \n",
    "        for  col in df_c.columns.drop(['CLASS', 'ID']):\n",
    "            self.feature_class_counts[col] = {}\n",
    "            for (name, group) in df_c.groupby(['CLASS']):\n",
    "                self.feature_class_counts[col][name] = len(group)\n",
    "                \n",
    "        self.labels = self.class_priors.keys()\n",
    "        \n",
    "        \n",
    "    def predict(self, df):\n",
    "        df_c = df.copy()\n",
    "        df_c = apply_column_filter(df_c, self.column_filter)\n",
    "        df_c = apply_bins(df_c, self.binning)\n",
    "        #print(df_c)\n",
    "        to_rtn = {}\n",
    "        # Hint 1: First apply the column filter and discretization\n",
    "        #\n",
    "        # Hint 2: Iterating over either columns or rows, and for each possible class label, calculate the relative\n",
    "        #         frequency of the observed feature value given the class (using feature_class_value_counts and \n",
    "        #         feature_class_counts) \n",
    "        #\n",
    "        # Hint 3: Calculate the non-normalized estimated class probabilities by multiplying the class priors to the\n",
    "        #         product of the relative frequencies\n",
    "        #\n",
    "        # Hint 4: Normalize the probabilities by dividing by the sum of the non-normalized probabilities; in case\n",
    "        #         this sum is zero, then set the probabilities to the class priors\n",
    "        \n",
    "        #frequency = self.feature_class_value_counts.copy()\n",
    "        #print(self.feature_class_counts)\n",
    "        for col in self.feature_class_value_counts.keys():\n",
    "            for lab in self.feature_class_value_counts[col].keys():\n",
    "                #print(lab)\n",
    "                x = self.feature_class_counts[col][lab[0]]\n",
    "                self.feature_class_value_counts[col][lab] = self.feature_class_value_counts[col][lab] / x\n",
    "        \n",
    "        \n",
    "        #Iterate over row \n",
    "        to_rtn = {}\n",
    "        for i,r in df_c.iterrows():\n",
    "            prob = {c:1.0 for c in self.labels}\n",
    "            for col in df_c.columns.drop(['CLASS', 'ID']):\n",
    "                v = str(r[col])\n",
    "                #Iterate over label\n",
    "                for l in self.labels:\n",
    "                    # +1 to avoid Zero frequency error\n",
    "                    #print('col', col)\n",
    "                    #print('tupla ', (l,v))\n",
    "                    prob[l] = prob[l] * (self.feature_class_value_counts[col].get((l,v), 0)+1)\n",
    "            to_rtn[i] = prob\n",
    "                    \n",
    "    \n",
    "        '''\n",
    "        for i, r in df_c.iterrows():\n",
    "            prob = {k:0 for k in self.labels}\n",
    "            #for each possible class label, calculate the relative frequency of the observed value given the class\n",
    "            #P(r[col] | )\n",
    "            for lab in self.labels: #Iterate over labels\n",
    "                #Iterate over the row r and get:\n",
    "                # results of the multiplication of relative frequencies\n",
    "                \n",
    "                # Take prior probability\n",
    "                prob[lab] = self.class_priors[lab]\n",
    "                for col, v in r.items():\n",
    "                    if col not in ['CLASS', 'ID']:\n",
    "                        # For each value of the test sample I get the relative frequency \n",
    "                        #using feature_class_value_counts and feature_class_counts\n",
    "\n",
    "                        #Multiply the prior to the relative frequency of the value given the class\n",
    "                        #print(self.feature_class_value_counts)\n",
    "                        #print(float(self.feature_class_value_counts.get(col, {}).get(v, {}).get(lab, 0)))\n",
    "                        #print(\"col\", col)\n",
    "                        #Add +1 on the get to avoid zero-frequency error\n",
    "                        prob[lab] *= ((self.feature_class_value_counts.get(col, {}).get((lab, str(v)), 0+1))/nb_model.feature_class_counts.get(col, {}).get(lab, 1))\n",
    "                \n",
    "            #Prob is a list containing the non-normalized probability of belonging to each class\n",
    "            #print(r['ID'])\n",
    "            #print(prob)\n",
    "            to_rtn[r['ID']] = prob\n",
    "            #print(len(to_rtn))\n",
    "            #print(to_rtn)\n",
    "             \n",
    "            \n",
    "            #Normalizing by dividing for the sum\n",
    "            for k in to_rtn.keys():\n",
    "                sum_tmp = sum(to_rtn[k])\n",
    "                print(sum_tmp)\n",
    "                to_rtn[k] = {l:(to_rtn[k][l]/sum_tmp) for l in self.labels}\n",
    "        '''\n",
    "        #print(to_rtn) \n",
    "        \n",
    "        to_rtn = pd.DataFrame.from_dict(to_rtn, orient='index', columns=self.labels)\n",
    "        return to_rtn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test labels  0      2\n",
      "1      2\n",
      "2      1\n",
      "3      1\n",
      "4      2\n",
      "      ..\n",
      "102    2\n",
      "103    2\n",
      "104    1\n",
      "105    2\n",
      "106    2\n",
      "Name: CLASS, Length: 107, dtype: int64\n",
      "Training time (3, 'equal-width'): 0.10 s.\n",
      "              2           1          7          5           3           6\n",
      "0     65.531823   75.511795  35.582445  45.596558   55.986328   48.888889\n",
      "1     30.775457   40.739276   9.216207  17.944336   45.117188   14.222222\n",
      "2     80.784371  172.345134  28.664498  41.989746  177.648926  104.296296\n",
      "3    105.207553  200.401319  46.112454  35.529785  177.648926   52.148148\n",
      "4    203.940794  148.133187  48.621975  51.814270  125.969238   32.592593\n",
      "..          ...         ...        ...        ...         ...         ...\n",
      "102  203.940794  148.133187  48.621975  51.814270  125.969238   32.592593\n",
      "103  203.940794  148.133187  48.621975  51.814270  125.969238   32.592593\n",
      "104  134.808322  108.251175  24.310988  27.634277   67.183594   16.296296\n",
      "105   33.971370   19.733087  21.644123  51.029205   26.660156   26.666667\n",
      "106   60.761930   54.293048  62.269280  61.066818   59.985352   73.333333\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (3, 'equal-width'): 0.05 s.\n",
      "Training time (3, 'equal-size'): 0.08 s.\n",
      "             2          1          7          5          3           6\n",
      "0    35.555967  31.363484  21.494144  26.586914  30.454102    8.166667\n",
      "1    18.094945  34.014624  25.903642  17.595703  39.276123  176.000000\n",
      "2    19.275050  36.282266  23.548766  17.595703  39.276123  117.333333\n",
      "3    35.172875  43.863394  17.014536  17.402344  22.781250    7.259259\n",
      "4    46.503328  22.839088  24.369206  32.958984  11.865234   12.000000\n",
      "..         ...        ...        ...        ...        ...         ...\n",
      "102  46.503328  22.839088  24.369206  32.958984  11.865234   12.000000\n",
      "103  43.729037  28.923632  16.175808  19.577637  32.392090   10.500000\n",
      "104  47.761208  36.988876  11.002068  29.910278  27.408691    6.351852\n",
      "105  23.099224  22.910751  25.394480  59.385498  33.602905   77.000000\n",
      "106  33.805611  27.777269  18.461520  41.528320  17.402344   28.000000\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (3, 'equal-size'): 0.06 s.\n",
      "Training time (5, 'equal-width'): 0.08 s.\n",
      "              2           1          7          5           3          6\n",
      "0     49.298089   32.377264  16.922228  11.843262   27.371094  11.666667\n",
      "1     12.966321   12.779059   8.358905  12.304688   15.996094  19.962963\n",
      "2     17.870250   30.784057   7.076322  19.995117   40.711212  22.814815\n",
      "3     44.650939   60.569712  28.011416  12.689209   44.214844  18.148148\n",
      "4     92.039463   88.834678  31.797379  18.328857   99.064697  28.518519\n",
      "..          ...         ...        ...        ...         ...        ...\n",
      "102  149.892839  103.162852  26.315072  32.075500  136.213959  36.666667\n",
      "103  149.892839  103.162852  26.315072  32.075500  136.213959  36.666667\n",
      "104   60.541513   77.134071  16.989380   9.775391   52.253906   9.074074\n",
      "105   13.437823   14.762344   6.558400   9.242188   16.242188   7.000000\n",
      "106   51.602453   42.916292  17.224411  27.757645   55.597534  67.222222\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (5, 'equal-width'): 0.04 s.\n",
      "Training time (5, 'equal-size'): 0.09 s.\n",
      "             2          1          7          5          3          6\n",
      "0    11.142206   7.534771  10.934595  14.683228   7.119141   4.666667\n",
      "1    10.053899  13.959384  14.536368  30.761719  19.638062  23.333333\n",
      "2     9.586275  17.766488   7.650720  15.380859  27.002335  11.666667\n",
      "3    11.397902  22.401805   8.186063   7.031250  16.824532   4.666667\n",
      "4    18.421867   9.853077  13.179561  22.659302   5.339355   7.000000\n",
      "..         ...        ...        ...        ...        ...        ...\n",
      "102  15.618540  11.302059  13.179561  20.393372   5.339355   6.222222\n",
      "103  22.425575  11.275416   6.750167  11.329651   8.342743   9.000000\n",
      "104   9.244439  14.779838   4.814906   5.220703   6.674194   2.722222\n",
      "105  12.374029  11.421314  14.536368  38.452148  17.852783  20.000000\n",
      "106  12.705811  11.847108  15.878963  21.752930   8.157349  21.333333\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (5, 'equal-size'): 0.05 s.\n",
      "Training time (10, 'equal-width'): 0.10 s.\n",
      "             2          1          7          5          3          6\n",
      "0    15.774940  11.519196   9.521892   7.712402  12.031250   6.222222\n",
      "1     9.349109   9.784883   5.682420  10.473633  14.396484  14.000000\n",
      "2     9.917184  16.410781   5.714891   8.569336  30.929947  13.333333\n",
      "3    16.978766  38.099354  12.891344   9.640503  31.582031  18.148148\n",
      "4    31.560940  15.988120   6.081725   8.898926  10.997314   7.000000\n",
      "..         ...        ...        ...        ...        ...        ...\n",
      "102  35.167904  15.988120   5.838456  11.123657  10.997314   7.000000\n",
      "103  41.263674  17.300928   5.351918  10.011292  21.841888   8.000000\n",
      "104  18.306915  39.295931   7.665123   6.855469  23.994141   9.074074\n",
      "105   6.723278   8.721586   5.180728   5.941406  10.283203   6.222222\n",
      "106  11.651588  12.185334   3.377619  10.011292  12.407227  22.222222\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (10, 'equal-width'): 0.05 s.\n",
      "Training time (10, 'equal-size'): 0.13 s.\n",
      "            2         1         7          5          3          6\n",
      "0    4.623590  4.772398  2.722500   3.559570   3.437500   3.000000\n",
      "1    5.126016  6.325366  5.106718   9.887695   7.007904  10.888889\n",
      "2    5.589241  8.478195  3.694271   5.273438  11.777172   8.166667\n",
      "3    6.354526  7.286569  3.685894   5.156250   7.690430   4.000000\n",
      "4    7.621362  5.437828  5.664549  10.196686   4.983398   4.666667\n",
      "..        ...       ...       ...        ...        ...        ...\n",
      "102  6.895518  5.777693  5.722350  10.196686   4.429688   4.666667\n",
      "103  8.922302  5.807620  3.685894   8.157349   5.537109   6.222222\n",
      "104  4.754773  6.046241  2.598750   2.531250   2.812500   2.000000\n",
      "105  4.994957  3.906026  4.330427   8.305664   4.894409   4.083333\n",
      "106  6.354526  5.022246  5.887109   9.970093   4.921875   9.333333\n",
      "\n",
      "[107 rows x 6 columns]\n",
      "Testing time (10, 'equal-size'): 0.06 s.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.429907</td>\n",
       "      <td>58437.726111</td>\n",
       "      <td>0.686261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.411215</td>\n",
       "      <td>10026.073505</td>\n",
       "      <td>0.747432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.514019</td>\n",
       "      <td>21742.186938</td>\n",
       "      <td>0.662361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.476636</td>\n",
       "      <td>1736.933032</td>\n",
       "      <td>0.774916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.532710</td>\n",
       "      <td>3027.182851</td>\n",
       "      <td>0.700434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.429907</td>\n",
       "      <td>268.491313</td>\n",
       "      <td>0.743817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Accuracy   Brier score       AUC\n",
       "3  equal-width  0.429907  58437.726111  0.686261\n",
       "   equal-size   0.411215  10026.073505  0.747432\n",
       "5  equal-width  0.514019  21742.186938  0.662361\n",
       "   equal-size   0.476636   1736.933032  0.774916\n",
       "10 equal-width  0.532710   3027.182851  0.700434\n",
       "   equal-size   0.429907    268.491313  0.743817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.csv\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.csv\")\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nb_model = NaiveBayes()\n",
    "\n",
    "print(\"test labels \", test_labels)\n",
    "\n",
    "nobins_values = [3,5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "parameters = [(nobins,bintype) for nobins in nobins_values for bintype in bintype_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "'''\n",
    "nb_model.fit(glass_train_df,nobins=10,bintype=\"equal-width\")\n",
    "\n",
    "#print(nb_model.feature_class_value_counts)\n",
    "\n",
    "prediction = nb_model.predict(glass_test_df)\n",
    "print(prediction)\n",
    "\n",
    "acc = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)]\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(\"\\n\\n\",nb_model.feature_class_counts)\n",
    "print(\"\\n\\n\",nb_model.labels)\n",
    "print(\"\\n\\n\",nb_model.class_priors)\n",
    "'''\n",
    "\n",
    "#print(test_labels)\n",
    "\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    nb_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = nb_model.predict(glass_test_df)\n",
    "    print(predictions)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "print()\n",
    "display(\"results\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.6355\n",
      "AUC on training set: 0.8217\n",
      "Brier score on training set: 3124.4335\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "nb_model.fit(glass_train_df)\n",
    "predictions = nb_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.4f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.4f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.4f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
